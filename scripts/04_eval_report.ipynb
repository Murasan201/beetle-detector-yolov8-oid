{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beetle Detection YOLOv8 評価レポート\n",
    "\n",
    "Open Images Dataset (OID) から学習したBeetle検出モデルの評価・可視化を行います。\n",
    "\n",
    "## 目的\n",
    "- 学習済みモデルの性能評価\n",
    "- mAP@0.5の確認（目標: ≥0.60）\n",
    "- PR曲線、混同行列の可視化\n",
    "- 誤検出の分析\n",
    "- 改善提案の検討"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なライブラリのインポート\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# YOLOv8関連\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "# 設定\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 学習結果の読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パス設定\n",
    "PROJECT_ROOT = Path('..')\n",
    "RUNS_DIR = PROJECT_ROOT / 'runs' / 'detect' / 'train'\n",
    "BEST_MODEL = RUNS_DIR / 'weights' / 'best.pt'\n",
    "LAST_MODEL = RUNS_DIR / 'weights' / 'last.pt'\n",
    "DATA_YAML = PROJECT_ROOT / 'datasets' / 'beetle-oid-yolo' / 'data.yaml'\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT.absolute()}\")\n",
    "print(f\"Best model: {BEST_MODEL}\")\n",
    "print(f\"Model exists: {BEST_MODEL.exists()}\")\n",
    "print(f\"Data yaml: {DATA_YAML}\")\n",
    "print(f\"Data exists: {DATA_YAML.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル読み込み\n",
    "if BEST_MODEL.exists():\n",
    "    model = YOLO(str(BEST_MODEL))\n",
    "    print(\"✅ Best model loaded successfully\")\n",
    "elif LAST_MODEL.exists():\n",
    "    model = YOLO(str(LAST_MODEL))\n",
    "    print(\"⚠️  Using last model (best not found)\")\n",
    "else:\n",
    "    print(\"❌ No trained model found. Please run training first.\")\n",
    "    model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 学習曲線の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習結果の画像確認\n",
    "results_images = [\n",
    "    ('results.png', 'Training Results'),\n",
    "    ('confusion_matrix.png', 'Confusion Matrix'),\n",
    "    ('F1_curve.png', 'F1 Score Curve'),\n",
    "    ('P_curve.png', 'Precision Curve'),\n",
    "    ('R_curve.png', 'Recall Curve'),\n",
    "    ('PR_curve.png', 'Precision-Recall Curve')\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (img_name, title) in enumerate(results_images):\n",
    "    img_path = RUNS_DIR / img_name\n",
    "    if img_path.exists():\n",
    "        img = Image.open(img_path)\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(title)\n",
    "        axes[i].axis('off')\n",
    "    else:\n",
    "        axes[i].text(0.5, 0.5, f'{title}\\n(Not found)', \n",
    "                    ha='center', va='center', transform=axes[i].transAxes)\n",
    "        axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 性能評価指標"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 検証データで評価実行\n",
    "if model and DATA_YAML.exists():\n",
    "    print(\"=== 検証データで評価実行 ===\")\n",
    "    \n",
    "    # 評価実行\n",
    "    metrics = model.val(data=str(DATA_YAML), plots=True, save_json=True)\n",
    "    \n",
    "    # 主要指標表示\n",
    "    print(\"\\n=== 主要性能指標 ===\")\n",
    "    print(f\"mAP@0.5: {metrics.box.map50:.4f}\")\n",
    "    print(f\"mAP@0.5:0.95: {metrics.box.map:.4f}\")\n",
    "    print(f\"Precision: {metrics.box.mp:.4f}\")\n",
    "    print(f\"Recall: {metrics.box.mr:.4f}\")\n",
    "    \n",
    "    # 目標達成確認\n",
    "    target_map50 = 0.60\n",
    "    if metrics.box.map50 >= target_map50:\n",
    "        print(f\"\\n✅ 目標達成！ mAP@0.5 = {metrics.box.map50:.4f} ≥ {target_map50}\")\n",
    "    else:\n",
    "        print(f\"\\n⚠️  目標未達成: mAP@0.5 = {metrics.box.map50:.4f} < {target_map50}\")\n",
    "        print(\"改善提案:\")\n",
    "        print(\"- より多くのデータでの学習\")\n",
    "        print(\"- オーグメンテーション調整\")\n",
    "        print(\"- より大きなモデル(yolov8s/m)の使用\")\n",
    "        print(\"- 学習エポック数の増加\")\n",
    "        \n",
    "else:\n",
    "    print(\"❌ 評価をスキップ（モデルまたはデータが見つかりません）\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. サンプル画像での推論テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 検証データからサンプル画像での推論\n",
    "if model and DATA_YAML.exists():\n",
    "    # 検証画像ディレクトリ\n",
    "    val_images_dir = PROJECT_ROOT / 'datasets' / 'beetle-oid-yolo' / 'images' / 'val'\n",
    "    \n",
    "    if val_images_dir.exists():\n",
    "        # 最初の数枚で推論テスト\n",
    "        sample_images = list(val_images_dir.glob('*.jpg'))[:6]\n",
    "        \n",
    "        if sample_images:\n",
    "            print(f\"=== サンプル推論（{len(sample_images)}枚） ===\")\n",
    "            \n",
    "            fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "            axes = axes.flatten()\n",
    "            \n",
    "            for i, img_path in enumerate(sample_images):\n",
    "                # 推論実行\n",
    "                results = model(str(img_path), conf=0.25)\n",
    "                \n",
    "                # 結果画像取得\n",
    "                annotated_img = results[0].plot()\n",
    "                \n",
    "                # 検出数表示\n",
    "                num_detections = len(results[0].boxes) if results[0].boxes is not None else 0\n",
    "                \n",
    "                axes[i].imshow(cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB))\n",
    "                axes[i].set_title(f'{img_path.name}\\nDetections: {num_detections}')\n",
    "                axes[i].axis('off')\n",
    "                \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "        else:\n",
    "            print(\"検証画像が見つかりません\")\n",
    "    else:\n",
    "        print(f\"検証画像ディレクトリが見つかりません: {val_images_dir}\")\n",
    "else:\n",
    "    print(\"推論テストをスキップ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 信頼度閾値の分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 異なる信頼度閾値での性能比較\n",
    "if model and val_images_dir.exists():\n",
    "    confidence_thresholds = [0.1, 0.25, 0.5, 0.7, 0.9]\n",
    "    sample_image = list(val_images_dir.glob('*.jpg'))[0]  # 最初の画像で実験\n",
    "    \n",
    "    print(f\"=== 信頼度閾値分析 ({sample_image.name}) ===\")\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(confidence_thresholds), figsize=(20, 4))\n",
    "    \n",
    "    detection_counts = []\n",
    "    \n",
    "    for i, conf in enumerate(confidence_thresholds):\n",
    "        results = model(str(sample_image), conf=conf)\n",
    "        annotated_img = results[0].plot()\n",
    "        \n",
    "        num_detections = len(results[0].boxes) if results[0].boxes is not None else 0\n",
    "        detection_counts.append(num_detections)\n",
    "        \n",
    "        axes[i].imshow(cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB))\n",
    "        axes[i].set_title(f'Conf: {conf}\\nDet: {num_detections}')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 検出数の推移グラフ\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(confidence_thresholds, detection_counts, 'o-', linewidth=2, markersize=8)\n",
    "    plt.xlabel('Confidence Threshold')\n",
    "    plt.ylabel('Number of Detections')\n",
    "    plt.title('Detection Count vs Confidence Threshold')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    for i, (conf, count) in enumerate(zip(confidence_thresholds, detection_counts)):\n",
    "        plt.annotate(f'{count}', (conf, count), textcoords=\"offset points\", \n",
    "                    xytext=(0,10), ha='center')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n推奨信頼度閾値:\")\n",
    "    print(\"- 高精度重視: 0.5-0.7\")\n",
    "    print(\"- バランス重視: 0.25-0.5\")\n",
    "    print(\"- 検出漏れ回避: 0.1-0.25\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. モデル情報とサマリー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル情報表示\n",
    "if model:\n",
    "    print(\"=== モデル情報 ===\")\n",
    "    print(f\"Model type: {model.model.__class__.__name__}\")\n",
    "    print(f\"Task: {model.task}\")\n",
    "    print(f\"Classes: {model.names}\")\n",
    "    \n",
    "    # モデルサイズ情報\n",
    "    model_info = model.info(verbose=False)\n",
    "    print(f\"\\nModel parameters: {sum(p.numel() for p in model.model.parameters()):,}\")\n",
    "    print(f\"Model size (MB): {os.path.getsize(BEST_MODEL) / (1024*1024):.2f}\" if BEST_MODEL.exists() else \"N/A\")\n",
    "    \n",
    "    # 推論速度テスト\n",
    "    if val_images_dir.exists():\n",
    "        test_image = list(val_images_dir.glob('*.jpg'))[0]\n",
    "        \n",
    "        # ウォームアップ\n",
    "        for _ in range(3):\n",
    "            _ = model(str(test_image), verbose=False)\n",
    "        \n",
    "        # 速度測定\n",
    "        import time\n",
    "        times = []\n",
    "        for _ in range(10):\n",
    "            start = time.time()\n",
    "            _ = model(str(test_image), verbose=False)\n",
    "            times.append(time.time() - start)\n",
    "        \n",
    "        avg_time = np.mean(times)\n",
    "        fps = 1.0 / avg_time\n",
    "        \n",
    "        print(f\"\\n=== 推論性能 ===\")\n",
    "        print(f\"Average inference time: {avg_time*1000:.2f} ms\")\n",
    "        print(f\"FPS: {fps:.2f}\")\n",
    "        print(f\"Device: {'GPU' if torch.cuda.is_available() and next(model.model.parameters()).is_cuda else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 評価サマリーと改善提案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"           BEETLE DETECTION MODEL EVALUATION REPORT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if model and 'metrics' in locals():\n",
    "    print(f\"\\n📊 PERFORMANCE METRICS:\")\n",
    "    print(f\"   mAP@0.5: {metrics.box.map50:.4f} {'✅' if metrics.box.map50 >= 0.60 else '⚠️ '}\")\n",
    "    print(f\"   mAP@0.5:0.95: {metrics.box.map:.4f}\")\n",
    "    print(f\"   Precision: {metrics.box.mp:.4f}\")\n",
    "    print(f\"   Recall: {metrics.box.mr:.4f}\")\n",
    "    \n",
    "    if 'avg_time' in locals():\n",
    "        print(f\"\\n⚡ INFERENCE PERFORMANCE:\")\n",
    "        print(f\"   Speed: {avg_time*1000:.2f} ms/image\")\n",
    "        print(f\"   FPS: {fps:.2f}\")\n",
    "    \n",
    "    print(f\"\\n🎯 TARGET ACHIEVEMENT:\")\n",
    "    if metrics.box.map50 >= 0.60:\n",
    "        print(f\"   ✅ Target mAP@0.5 ≥ 0.60 ACHIEVED!\")\n",
    "        print(f\"   🎉 Model ready for production use\")\n",
    "    else:\n",
    "        print(f\"   ⚠️  Target mAP@0.5 ≥ 0.60 NOT reached\")\n",
    "        print(f\"   📈 Consider improvements below\")\n",
    "    \n",
    "    print(f\"\\n💡 IMPROVEMENT SUGGESTIONS:\")\n",
    "    if metrics.box.map50 < 0.60:\n",
    "        print(f\"   🔹 Increase dataset size (current: test mode)\")\n",
    "        print(f\"   🔹 Use larger model (yolov8s or yolov8m)\")\n",
    "        print(f\"   🔹 Extend training epochs\")\n",
    "        print(f\"   🔹 Adjust data augmentation\")\n",
    "    else:\n",
    "        print(f\"   🔹 Consider model optimization for speed\")\n",
    "        print(f\"   🔹 Evaluate on more diverse test data\")\n",
    "        print(f\"   🔹 Fine-tune confidence threshold\")\n",
    "        \n",
    "else:\n",
    "    print(\"\\n❌ Evaluation incomplete - please ensure model training is completed\")\n",
    "\n",
    "print(f\"\\n📁 OUTPUT FILES:\")\n",
    "print(f\"   📋 This report: scripts/04_eval_report.ipynb\")\n",
    "print(f\"   🏆 Best model: {BEST_MODEL}\")\n",
    "print(f\"   📊 Training plots: {RUNS_DIR}/*.png\")\n",
    "print(f\"   📄 Detailed logs: {RUNS_DIR}/\")\n",
    "\n",
    "print(f\"\\n🔗 NEXT STEPS:\")\n",
    "print(f\"   1️⃣  Test with custom images: python scripts/05_infer_cli.py\")\n",
    "print(f\"   2️⃣  Deploy model for production use\")\n",
    "print(f\"   3️⃣  Consider Google Colab for full-scale training\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}