{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beetle Detection YOLOv8 è©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆ\n",
    "\n",
    "Open Images Dataset (OID) ã‹ã‚‰å­¦ç¿’ã—ãŸBeetleæ¤œå‡ºãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ãƒ»å¯è¦–åŒ–ã‚’è¡Œã„ã¾ã™ã€‚\n",
    "\n",
    "## ç›®çš„\n",
    "- å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½è©•ä¾¡\n",
    "- mAP@0.5ã®ç¢ºèªï¼ˆç›®æ¨™: â‰¥0.60ï¼‰\n",
    "- PRæ›²ç·šã€æ··åŒè¡Œåˆ—ã®å¯è¦–åŒ–\n",
    "- èª¤æ¤œå‡ºã®åˆ†æ\n",
    "- æ”¹å–„ææ¡ˆã®æ¤œè¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# YOLOv8é–¢é€£\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "# è¨­å®š\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. å­¦ç¿’çµæœã®èª­ã¿è¾¼ã¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‘ã‚¹è¨­å®š\n",
    "PROJECT_ROOT = Path('..')\n",
    "RUNS_DIR = PROJECT_ROOT / 'runs' / 'detect' / 'train'\n",
    "BEST_MODEL = RUNS_DIR / 'weights' / 'best.pt'\n",
    "LAST_MODEL = RUNS_DIR / 'weights' / 'last.pt'\n",
    "DATA_YAML = PROJECT_ROOT / 'datasets' / 'beetle-oid-yolo' / 'data.yaml'\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT.absolute()}\")\n",
    "print(f\"Best model: {BEST_MODEL}\")\n",
    "print(f\"Model exists: {BEST_MODEL.exists()}\")\n",
    "print(f\"Data yaml: {DATA_YAML}\")\n",
    "print(f\"Data exists: {DATA_YAML.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿\n",
    "if BEST_MODEL.exists():\n",
    "    model = YOLO(str(BEST_MODEL))\n",
    "    print(\"âœ… Best model loaded successfully\")\n",
    "elif LAST_MODEL.exists():\n",
    "    model = YOLO(str(LAST_MODEL))\n",
    "    print(\"âš ï¸  Using last model (best not found)\")\n",
    "else:\n",
    "    print(\"âŒ No trained model found. Please run training first.\")\n",
    "    model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. å­¦ç¿’æ›²ç·šã®å¯è¦–åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å­¦ç¿’çµæœã®ç”»åƒç¢ºèª\n",
    "results_images = [\n",
    "    ('results.png', 'Training Results'),\n",
    "    ('confusion_matrix.png', 'Confusion Matrix'),\n",
    "    ('F1_curve.png', 'F1 Score Curve'),\n",
    "    ('P_curve.png', 'Precision Curve'),\n",
    "    ('R_curve.png', 'Recall Curve'),\n",
    "    ('PR_curve.png', 'Precision-Recall Curve')\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (img_name, title) in enumerate(results_images):\n",
    "    img_path = RUNS_DIR / img_name\n",
    "    if img_path.exists():\n",
    "        img = Image.open(img_path)\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(title)\n",
    "        axes[i].axis('off')\n",
    "    else:\n",
    "        axes[i].text(0.5, 0.5, f'{title}\\n(Not found)', \n",
    "                    ha='center', va='center', transform=axes[i].transAxes)\n",
    "        axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. æ€§èƒ½è©•ä¾¡æŒ‡æ¨™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡å®Ÿè¡Œ\n",
    "if model and DATA_YAML.exists():\n",
    "    print(\"=== æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡å®Ÿè¡Œ ===\")\n",
    "    \n",
    "    # è©•ä¾¡å®Ÿè¡Œ\n",
    "    metrics = model.val(data=str(DATA_YAML), plots=True, save_json=True)\n",
    "    \n",
    "    # ä¸»è¦æŒ‡æ¨™è¡¨ç¤º\n",
    "    print(\"\\n=== ä¸»è¦æ€§èƒ½æŒ‡æ¨™ ===\")\n",
    "    print(f\"mAP@0.5: {metrics.box.map50:.4f}\")\n",
    "    print(f\"mAP@0.5:0.95: {metrics.box.map:.4f}\")\n",
    "    print(f\"Precision: {metrics.box.mp:.4f}\")\n",
    "    print(f\"Recall: {metrics.box.mr:.4f}\")\n",
    "    \n",
    "    # ç›®æ¨™é”æˆç¢ºèª\n",
    "    target_map50 = 0.60\n",
    "    if metrics.box.map50 >= target_map50:\n",
    "        print(f\"\\nâœ… ç›®æ¨™é”æˆï¼ mAP@0.5 = {metrics.box.map50:.4f} â‰¥ {target_map50}\")\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸  ç›®æ¨™æœªé”æˆ: mAP@0.5 = {metrics.box.map50:.4f} < {target_map50}\")\n",
    "        print(\"æ”¹å–„ææ¡ˆ:\")\n",
    "        print(\"- ã‚ˆã‚Šå¤šãã®ãƒ‡ãƒ¼ã‚¿ã§ã®å­¦ç¿’\")\n",
    "        print(\"- ã‚ªãƒ¼ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³èª¿æ•´\")\n",
    "        print(\"- ã‚ˆã‚Šå¤§ããªãƒ¢ãƒ‡ãƒ«(yolov8s/m)ã®ä½¿ç”¨\")\n",
    "        print(\"- å­¦ç¿’ã‚¨ãƒãƒƒã‚¯æ•°ã®å¢—åŠ \")\n",
    "        \n",
    "else:\n",
    "    print(\"âŒ è©•ä¾¡ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆãƒ¢ãƒ‡ãƒ«ã¾ãŸã¯ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã§ã®æ¨è«–ãƒ†ã‚¹ãƒˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã§ã®æ¨è«–\n",
    "if model and DATA_YAML.exists():\n",
    "    # æ¤œè¨¼ç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n",
    "    val_images_dir = PROJECT_ROOT / 'datasets' / 'beetle-oid-yolo' / 'images' / 'val'\n",
    "    \n",
    "    if val_images_dir.exists():\n",
    "        # æœ€åˆã®æ•°æšã§æ¨è«–ãƒ†ã‚¹ãƒˆ\n",
    "        sample_images = list(val_images_dir.glob('*.jpg'))[:6]\n",
    "        \n",
    "        if sample_images:\n",
    "            print(f\"=== ã‚µãƒ³ãƒ—ãƒ«æ¨è«–ï¼ˆ{len(sample_images)}æšï¼‰ ===\")\n",
    "            \n",
    "            fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "            axes = axes.flatten()\n",
    "            \n",
    "            for i, img_path in enumerate(sample_images):\n",
    "                # æ¨è«–å®Ÿè¡Œ\n",
    "                results = model(str(img_path), conf=0.25)\n",
    "                \n",
    "                # çµæœç”»åƒå–å¾—\n",
    "                annotated_img = results[0].plot()\n",
    "                \n",
    "                # æ¤œå‡ºæ•°è¡¨ç¤º\n",
    "                num_detections = len(results[0].boxes) if results[0].boxes is not None else 0\n",
    "                \n",
    "                axes[i].imshow(cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB))\n",
    "                axes[i].set_title(f'{img_path.name}\\nDetections: {num_detections}')\n",
    "                axes[i].axis('off')\n",
    "                \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "        else:\n",
    "            print(\"æ¤œè¨¼ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "    else:\n",
    "        print(f\"æ¤œè¨¼ç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {val_images_dir}\")\n",
    "else:\n",
    "    print(\"æ¨è«–ãƒ†ã‚¹ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ä¿¡é ¼åº¦é–¾å€¤ã®åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç•°ãªã‚‹ä¿¡é ¼åº¦é–¾å€¤ã§ã®æ€§èƒ½æ¯”è¼ƒ\n",
    "if model and val_images_dir.exists():\n",
    "    confidence_thresholds = [0.1, 0.25, 0.5, 0.7, 0.9]\n",
    "    sample_image = list(val_images_dir.glob('*.jpg'))[0]  # æœ€åˆã®ç”»åƒã§å®Ÿé¨“\n",
    "    \n",
    "    print(f\"=== ä¿¡é ¼åº¦é–¾å€¤åˆ†æ ({sample_image.name}) ===\")\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(confidence_thresholds), figsize=(20, 4))\n",
    "    \n",
    "    detection_counts = []\n",
    "    \n",
    "    for i, conf in enumerate(confidence_thresholds):\n",
    "        results = model(str(sample_image), conf=conf)\n",
    "        annotated_img = results[0].plot()\n",
    "        \n",
    "        num_detections = len(results[0].boxes) if results[0].boxes is not None else 0\n",
    "        detection_counts.append(num_detections)\n",
    "        \n",
    "        axes[i].imshow(cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB))\n",
    "        axes[i].set_title(f'Conf: {conf}\\nDet: {num_detections}')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # æ¤œå‡ºæ•°ã®æ¨ç§»ã‚°ãƒ©ãƒ•\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(confidence_thresholds, detection_counts, 'o-', linewidth=2, markersize=8)\n",
    "    plt.xlabel('Confidence Threshold')\n",
    "    plt.ylabel('Number of Detections')\n",
    "    plt.title('Detection Count vs Confidence Threshold')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    for i, (conf, count) in enumerate(zip(confidence_thresholds, detection_counts)):\n",
    "        plt.annotate(f'{count}', (conf, count), textcoords=\"offset points\", \n",
    "                    xytext=(0,10), ha='center')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\næ¨å¥¨ä¿¡é ¼åº¦é–¾å€¤:\")\n",
    "    print(\"- é«˜ç²¾åº¦é‡è¦–: 0.5-0.7\")\n",
    "    print(\"- ãƒãƒ©ãƒ³ã‚¹é‡è¦–: 0.25-0.5\")\n",
    "    print(\"- æ¤œå‡ºæ¼ã‚Œå›é¿: 0.1-0.25\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã¨ã‚µãƒãƒªãƒ¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ¢ãƒ‡ãƒ«æƒ…å ±è¡¨ç¤º\n",
    "if model:\n",
    "    print(\"=== ãƒ¢ãƒ‡ãƒ«æƒ…å ± ===\")\n",
    "    print(f\"Model type: {model.model.__class__.__name__}\")\n",
    "    print(f\"Task: {model.task}\")\n",
    "    print(f\"Classes: {model.names}\")\n",
    "    \n",
    "    # ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºæƒ…å ±\n",
    "    model_info = model.info(verbose=False)\n",
    "    print(f\"\\nModel parameters: {sum(p.numel() for p in model.model.parameters()):,}\")\n",
    "    print(f\"Model size (MB): {os.path.getsize(BEST_MODEL) / (1024*1024):.2f}\" if BEST_MODEL.exists() else \"N/A\")\n",
    "    \n",
    "    # æ¨è«–é€Ÿåº¦ãƒ†ã‚¹ãƒˆ\n",
    "    if val_images_dir.exists():\n",
    "        test_image = list(val_images_dir.glob('*.jpg'))[0]\n",
    "        \n",
    "        # ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—\n",
    "        for _ in range(3):\n",
    "            _ = model(str(test_image), verbose=False)\n",
    "        \n",
    "        # é€Ÿåº¦æ¸¬å®š\n",
    "        import time\n",
    "        times = []\n",
    "        for _ in range(10):\n",
    "            start = time.time()\n",
    "            _ = model(str(test_image), verbose=False)\n",
    "            times.append(time.time() - start)\n",
    "        \n",
    "        avg_time = np.mean(times)\n",
    "        fps = 1.0 / avg_time\n",
    "        \n",
    "        print(f\"\\n=== æ¨è«–æ€§èƒ½ ===\")\n",
    "        print(f\"Average inference time: {avg_time*1000:.2f} ms\")\n",
    "        print(f\"FPS: {fps:.2f}\")\n",
    "        print(f\"Device: {'GPU' if torch.cuda.is_available() and next(model.model.parameters()).is_cuda else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. è©•ä¾¡ã‚µãƒãƒªãƒ¼ã¨æ”¹å–„ææ¡ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"           BEETLE DETECTION MODEL EVALUATION REPORT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if model and 'metrics' in locals():\n",
    "    print(f\"\\nğŸ“Š PERFORMANCE METRICS:\")\n",
    "    print(f\"   mAP@0.5: {metrics.box.map50:.4f} {'âœ…' if metrics.box.map50 >= 0.60 else 'âš ï¸ '}\")\n",
    "    print(f\"   mAP@0.5:0.95: {metrics.box.map:.4f}\")\n",
    "    print(f\"   Precision: {metrics.box.mp:.4f}\")\n",
    "    print(f\"   Recall: {metrics.box.mr:.4f}\")\n",
    "    \n",
    "    if 'avg_time' in locals():\n",
    "        print(f\"\\nâš¡ INFERENCE PERFORMANCE:\")\n",
    "        print(f\"   Speed: {avg_time*1000:.2f} ms/image\")\n",
    "        print(f\"   FPS: {fps:.2f}\")\n",
    "    \n",
    "    print(f\"\\nğŸ¯ TARGET ACHIEVEMENT:\")\n",
    "    if metrics.box.map50 >= 0.60:\n",
    "        print(f\"   âœ… Target mAP@0.5 â‰¥ 0.60 ACHIEVED!\")\n",
    "        print(f\"   ğŸ‰ Model ready for production use\")\n",
    "    else:\n",
    "        print(f\"   âš ï¸  Target mAP@0.5 â‰¥ 0.60 NOT reached\")\n",
    "        print(f\"   ğŸ“ˆ Consider improvements below\")\n",
    "    \n",
    "    print(f\"\\nğŸ’¡ IMPROVEMENT SUGGESTIONS:\")\n",
    "    if metrics.box.map50 < 0.60:\n",
    "        print(f\"   ğŸ”¹ Increase dataset size (current: test mode)\")\n",
    "        print(f\"   ğŸ”¹ Use larger model (yolov8s or yolov8m)\")\n",
    "        print(f\"   ğŸ”¹ Extend training epochs\")\n",
    "        print(f\"   ğŸ”¹ Adjust data augmentation\")\n",
    "    else:\n",
    "        print(f\"   ğŸ”¹ Consider model optimization for speed\")\n",
    "        print(f\"   ğŸ”¹ Evaluate on more diverse test data\")\n",
    "        print(f\"   ğŸ”¹ Fine-tune confidence threshold\")\n",
    "        \n",
    "else:\n",
    "    print(\"\\nâŒ Evaluation incomplete - please ensure model training is completed\")\n",
    "\n",
    "print(f\"\\nğŸ“ OUTPUT FILES:\")\n",
    "print(f\"   ğŸ“‹ This report: scripts/04_eval_report.ipynb\")\n",
    "print(f\"   ğŸ† Best model: {BEST_MODEL}\")\n",
    "print(f\"   ğŸ“Š Training plots: {RUNS_DIR}/*.png\")\n",
    "print(f\"   ğŸ“„ Detailed logs: {RUNS_DIR}/\")\n",
    "\n",
    "print(f\"\\nğŸ”— NEXT STEPS:\")\n",
    "print(f\"   1ï¸âƒ£  Test with custom images: python scripts/05_infer_cli.py\")\n",
    "print(f\"   2ï¸âƒ£  Deploy model for production use\")\n",
    "print(f\"   3ï¸âƒ£  Consider Google Colab for full-scale training\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}